---
layout: post
title:  "AIXDL 프로젝트 - 1"
summary: "차량 공유 서비스의 차량 파손 여부를 CNN을 활용하여 판단"
author: taehun
date: '2020-12-02 16:53:00 +0900'
category: Python
thumbnail: /assets/img/posts/thumbnail-1.png
keywords: AI+X:DeepLearning, Dataset, VGGNet, Pre-trained model, ImageNet
permalink: /blog/project-1
---
----------
## **Index**
----------
 - **Introduction**
 1. 필요성
 1. 목표<br><br>
 
 - **Dataset**
 1. 사용한 데이터셋
 1. 데이터 전처리 <br><br>
 
 - **VGGNet Model** <br><br>
 
 - **Details**
 1. 이미지 데이터의 차량 여부 판단(Pre-trained VGG16 model)
 1. 차량의 파손 여부 판단(직접 학습한 VGGNet model)<br><br>

 - **Evaulation**<br><br>

 - **Conclusion & Improvement**<br><br>
 
 - **Reference**<br><br>

------------------------
## **Introduction**
-------------------------

#### 1. 필요성
 - 미래 모빌리티 산업에서 공유 서비스는 핵심 개념 중 하나이다. 대표적인 예로 '쏘카', '그린카' 등의 차량 공유 서비스뿐만 아니라, '따릉이','beam','씽씽'과 같은 자전거, 전동 킥보드의 공유 서비스도 있다. 공유서비스의 대상인 차량, 킥보드 등은 단독으로 소유하는 소유물이 아니기에, 파손 및 손상 여부에 대한 과실 판정을 제 때에, 정확하게 할 필요가 있다.<br><br> 렌트카의 경우 대여 및 반납시 대여자가 차량의 파손여부를 직접 체크한다. 차량 확인 과정에서 발견하지 못한, 즉 대여자의 과실이 아닌 손상으로 인해 발생하는 문제를 확실히 해결하기 위해서는 적절한 시스템이 필요할 것이다. 이 문제점을 해결하기 위해서 딥러닝의 이미지 분류를 이용해서 해결해보고자 한다.<br><br>

#### 2. 목표
 - 본 프로젝트에서는 딥러닝의 Image Classification을 활용해서 문제를 해결하고자 한다. 임의의 이미지 데이터를 입력했을 때 차량인지 아닌지를 판단하고, 만약 차량이 맞다면 차량의 파손 유무를 판단하는 것이 프로젝트의 최종 목표이다. <br><br> 판단은 2개의  Gate를 통해 이루어진다. Gate1에서는  Pre-trained model(VGGNet )을 활용하여 차량 여부 및 차량의 종류를 판단하고, Gate2에서는 직접 학습시킨 모델로  파손 여부를 판단한다.<br>
 
![Image Alt 텍스트](/assets/img/Gate.png){: width="700" height="300" text-align="center"}<br>
*모델 알고리즘 개략도*

----------------
## **Dataset**
----------------

#### 1. 사용 데이터셋
- data1 폴더 : Normal/Damaged 차량에 대한 이미지 파일 각 500개, 총 1000개(Gate1)
- data2 폴더 : Training data 600개(Normal/Damaged 각 300개)<br>　　 　　　　Validation data 200개(Normal/Damaged 각 100개)(Gate2)<br>


<div style="width:350px; height:350px; float:left; margin-right:10px">
 <img src="/assets/img/normal.jpg" width="350px" height="350px">
<!--  <figcaption>Normal car image</figcaption> -->
</div>
<div style="width:350px; height:350px; float:left;">
 <img src="/assets/img/damaged.jpg" width="350px" height="352px"> 
<!--  <figcaption>Damaged car image</figcaption> -->
</div>

#### 2. 데이터 전처리 과정

```python
def prepare_image(img_path):
    img = load_img(img_path, target_size=(224, 224))
    x = img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    return x
```

- Pre-trained VGG16 model에서 학습된 image size는 224×224이므로, input image를 224×224로 변환하는 과정

-------------------
## **VGGNet Model**
-------------------
![Image Alt 텍스트](/assets/img/VGGNet.png){: width="700" height="300"}
 
-----------------
## **Details**
-----------------
#### 1.이미지 데이터의 차량 여부 판단(Pre-trained VGG16 model)
　 **1)get_predictions(preds,top=5) function**

```python
def get_predictions(preds, top=5):
    global CLASS_INDEX
    if len(preds.shape) != 2 or preds.shape[1] != 1000:
        raise ValueError('`decode_predictions` expects '
                         'a batch of predictions '
                         '(i.e. a 2D array of shape (samples, 1000)). '
                         'Found array with shape: ' + str(preds.shape))
    if CLASS_INDEX is None:
        fpath = get_file('imagenet_class_index.json',
                         CLASS_INDEX_PATH,
                         cache_subdir='models')
        CLASS_INDEX = json.load(open(fpath))
    results = []
    for pred in preds:
        top_indices = pred.argsort()[-top:][::-1]
        #argsort()는 numpy 패키지의 메소드로, 원소들중 가장 작은 값을 가지는 원소의 인덱스부터 차례대로 리턴함
        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]
        list_A = []
        for k in range(top):
        	list_A.append(result[i][1:])
        result.sort(key=lambda x: x[2], reverse=True)
        results.append(result)
    return results
```
```python
vgg16 = VGG16(weights='imagenet')

y = prepare_image('image_file.jpg')
preds = vgg16.predict(y)
print(get_predictions(preds, top=5))
```
- get_predictions(preds, top=5) 결과
![Image Alt 텍스트](/assets/img/pred_top5.png){: width="700" height="30"}

- 변수 preds는 data1 폴더의 dataset을 resizing 후 VGG16(weight='imagenet')으로 예측한 결과물이며, 1000개의 class에 대한 확률값을 나타내기에 차원은 (1,1000)이다.
- get_prediction 함수는 예측한 class 중 상위 5개의 class name과 확률값을 반환한다.<br><br>

　 **2)get_car_categories() function**<br><br>

#### 2.차량의 파손 여부 판단(직접 학습한 VGGNet model)
