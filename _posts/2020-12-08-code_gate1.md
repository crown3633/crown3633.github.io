---
layout: post
title:  "AIXDL - Code (Gate1)"
summary: "차량 공유 서비스의 차량 파손 여부를 CNN을 활용하여 판단"
author: taehun
date: '2020-12-08 04:04:00 +0900'
category: Python
toc : true
toc_sticky : true
thumbnail: /assets/img/posts/thumbnail-2.png
keywords: AI+X:DeepLearning, Dataset, VGGNet, Pre-trained model, ImageNet
permalink: /blog/code_gate1
---
----------
## Gate 1 code
----------
```python
 #!/usr/bin/env python
 # coding: utf-8

 #data0 - all car images, including whole and damaged

 #01-car_or_not.py는 train은 하지 않음. 
 #ImageNet으로 학습한 VGGNet 모델을 이용해서 predictiong하기에 결과값이 데이터와 아주 무관하진 않지만 거의 무관함
#그래도 영향을 끼치는 부분은 top5만 가지고 한다는 점임. 
#이미지 데이터마다 예측한 상위 5개의 class를 제외하고는 car_categories에 포함되지 않으므로 미미한 영향을 끼치긴 함
import urllib.request
from IPython.display import Image, display, clear_output
from collections import Counter, defaultdict

import matplotlib.pyplot as plt
import seaborn as sns 
#get_ipython().run_line_magic('matplotlib', 'inline')

import json
import pickle as pk
from sklearn.metrics import classification_report, confusion_matrix

import os
import h5py
import numpy as np
import pandas as pd

from keras.utils.data_utils import get_file
from keras.applications.vgg16 import VGG16
from keras.applications.inception_v3 import InceptionV3
from keras.applications.imagenet_utils import preprocess_input, decode_predictions
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras.models import Sequential, load_model
from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.utils.np_utils import to_categorical
from keras import optimizers
from keras.callbacks import ModelCheckpoint, History


CLASS_INDEX = None
CLASS_INDEX_PATH = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'

#from Keras GitHub
def get_predictions(preds, top=5):
#preds : predictions 줄인 것, 차원은 (1,1000)이고, 모델에 의해서 학습된 1000개의 class에 대한 각각의 확률값을 나타낸 것, 자료형은 numpy.ndarray
    global CLASS_INDEX
    if len(preds.shape) != 2 or preds.shape[1] != 1000:
    	#len은 [] 의 개수와 같음. preds.shape[1]은 preds의 원소 수가 1000개로 학습되어 있기에 1000으로 설정된 것 
        raise ValueError('`decode_predictions` expects '
                         'a batch of predictions '
                         '(i.e. a 2D array of shape (samples, 1000)). '
                         'Found array with shape: ' + str(preds.shape))
    if CLASS_INDEX is None:
        fpath = get_file('imagenet_class_index.json',
                         CLASS_INDEX_PATH,
                         cache_subdir='models')
        CLASS_INDEX = json.load(open(fpath))
    results = []
    for pred in preds:
        top_indices = pred.argsort()[-top:][::-1]
        #argsort()는 numpy 패키지의 메소드로, 원소들중 가장 작은 값을 가지는 원소의 인덱스부터 차례대로 리턴함
        #[-top:]은 뒤에서부터 5개를 출력하는 것인데, 이 때 가장 큰 원소값을 가지는 인덱스부터 나타내기 위해서는 [::-1]를 이용해서 거꾸로 출력해야 함
        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]
        list_A = []
        for k in range(top):
        	list_A.append(result[i][1:])
        #print(list_A)
        result.sort(key=lambda x: x[2], reverse=True)
        #sort() 메서드는 reverse = True일 경우 내림차순이 된다. key=x[2]이므로 x[2] 즉, result[2]를 기준으로 내림차순하라는 뜻
        #result = sorted(result, key = lambda x:x[2], reverse = True)
        #sort()와 sorted()는 같은 역할을 함. 하지만 sort의 경우 반환값은 None이므로 print(result.sort(~~)는 None이 출력됨)
        results.append(result)
    return results

vgg16 = VGG16(weights='imagenet')
#Pretrained-model로, imagenet으로 학습된 가중치를 불러오는 것

vgg16.save('vgg16.h5')
vgg16.save_weights('vgg16_weights.h5')
#그냥 모델을 해당 디렉토리에 저장하는 것

root_dir = "/home/ubuntu/project/"

Image(root_dir + "data1/0001.jpg", width=200)

def prepare_image(img_path):
#image input을 넣으면 model에 넣을 수 있게 조정해주는 함수
    img = load_img(img_path, target_size=(224, 224)) 
    #이미지 파일을 224*224로 불러옴. RGB까지 아마 224*224*3일 것
    x = img_to_array(img)
    x = np.expand_dims(x, axis=0)
    #Mini-batch SGD를 사용하기 위해 차원을 하나 추가하는 것. axis=0은 첫번째 성분에 추가한다는 뜻. Mini-batch SGD를 위해 전체 학습 데이터에서 랜덤샘플링을 통해 미니 배치를 만들 때 그 미니 배치의 크기를 뜻함
    x = preprocess_input(x)
    return x
    #정리하면, prepare_image(img_path) 과정은 이미지를 불러오고, 그 이미지를 3차원의 array로 변경한 다음 샘플링을 위해 차원을 추가하고, preprocess 과정을 거쳐서 model에 input으로 넣을 수 있도록 하는 함수


#Testing with different models

print(vgg16.summary())
y = prepare_image(root_dir + "data1" + "/0011.jpg")
preds = vgg16.predict(y)
#VGG16과 VGG19의 차이는 layer 갯수. VGG16은 16-layer
#print(preds)
#print(preds.shape)
#print(len(preds.shape))

pred_result = []
for i in range(4):
  pred_result.append(get_predictions(preds, top=5)[0][i][1:])

#print(pred_result)

for i in range(5):
	print(get_predictions(preds,top=5)[0][i][1:])

#Using VGG16 as Gate

def get_car_categories():
#해당 폴더에 있는 모든 이미지 파일들에 대해 vehicle 종류를 prediction.
    d = defaultdict(float)
    #dict의 value 값을 float로 default 시키는 메서드. value 값을 지정하지 않고 key 값만 입력하는 경우 float의 경우에는 0.0으로 세팅됨
    img_list = os.listdir("data1")
    #os.listdir(path)는 path에 있는 파일과 디렉토리의 이름을 list로 리턴. path는 지정하지 않으면 현재의 working directory를 시용
    for i, img_path in enumerate(img_list):
    #enumerate는 list의 각 원소를 인덱스 번호와 원소의 쌍으로, tuple형태로 반환함
        img = prepare_image(root_dir + "data1/"+ img_path)
        out = vgg16.predict(img)
        top = []
        # for i in range(5):
        # 	top.append(get_predictions(out,top=5)[0][i][1:])
        top = get_predictions(out, top=5)
        for j in top[0]:
        #top[0]에는 3가지 성분이 있음. 1000개 class중 고유 이름(j[0], ex)'n5324', class의 이름(label)(j[1]), 확률값(j[2])
        #그리고 j는 총 5가지임.top[0]에 5개의 성분이 있기 때문.
        #d[j[0:2]]가 갖는 의미는 j의 0행부터 1행까지, 2개의 성분을 가진 튜플들이 dict형 변수 d의 key값이 된다는 것. 그리고 확률값인 j[2]는 해당 key값에 대한 value가 됨
            d[j[0:2]] += j[2]
            #d[j[1:2]] += j[2]
            #폴더 내에 있는 모든 이미지 파일들에 대해 prediction 결과를 dict형 변수 d에 계속 저장
            #Q.이미지마다 예측된 결과인 top5는 다른데, d[j[0:2]] += j[2] 과정을 통해 같은 key값을 가진, 즉 같은 class들에 대해서는 확률값을 더해줌.
            #=> 아마 이걸 더해주는 이유는 내가 모아놓은 이미지 데이터에 대해서 어떤 종류의 데이터가 가장 많은지, 그 분포를 예측하기 위함인 것 같음
        if i % 100 == 0:
            print(i, "/" , len(img_list), "complete")
    print("Done\n")
    return Counter(d)
    #Counter 메서드는 list나 dict형 변수에서 같은 key 값들의 갯수를 세는 역할을 함
    #또한 Counter 메서드는dict형의 value 값이 높은 것부터 순차적으로 제시됨

cat_counter = get_car_categories()

with open("cat_counter.pk", "wb") as f:
	#pickle을 이용하여 데이터 저장 & 불러오기 => 데이터 저장 & 불러올 때 유용한 라이브러리
	#with open(‘파일경로’, 기타옵션) as file 
	#- open 함수를 통해 파일 읽기/쓰기 가능 
	#- ‘r’ : read (읽기 모드로 파일 열기) 
	#- ‘w’ : write (쓰기 모드로 파일 열기)
	# - ‘a’ : add (추가 모드로 파일 열기. 기존 파일의 내용 끝에 새 내용을 추가하여 기록하는 것) 
	#- ‘wb’ : write + binary (이진 파일을 쓰기 모드로 연다. 쓰는 데이터는 raw 데이터 그대로 쓰인다.) 
	#- ‘rb’ : read + binary (이진 파일 읽기 모드) 
	#- ‘ab’
    pk.dump(cat_counter,f,-1)
    #pk 파일로 저장
    #마지막 -1은 protocol로 highest binary protocol을 의미한다 함. 없어도 무방


#Load Pickle Point

with open("cat_counter.pk", "rb") as f:
    cat_counter = pk.load(f)
    #pk 파일 불러오기

list_A = list(cat_counter.keys())
#print(len(list_A))

car_categories = [k for k, v in cat_counter.most_common()[:50]]
#most_common은 dict형에서 value값이 큰 순서대로 정한 갯수만큼 출력하는 것. 출력할 때 key, value를 출력함

#Evaluating Car Categories from Imagenet

def evaluate_car_categories(car_categories):
    #이 evaluate_car_categories는 위에서 한번 분류한 car_categories를 가지고 failed_img를 만드는 함수
    img_list = os.listdir("data1")
    #os.listdir(path)는 path에 있는 파일과 디렉토리의 이름을 list로 리턴. path는 지정하지 않으면 현재의 working directory를 시용
    num = 0
    failed_img = []
    for i, img_path in enumerate(img_list):
    #enumerate는 list의 각 원소를 인덱스 번호와 원소의 쌍으로, tuple형태로 반환함
        img = prepare_image("data1/"+img_path)
        out = vgg16.predict(img)
        if i==1: print(out.shape)
        top = get_predictions(out, top=5)
        for j in top[0]:
            if j[0:2] in car_categories:
            #지금 들어간 이미지 데이터의 prediction 결과(j[0:2])가 내가 가진 데이터셋에서 추출한 상위 50개(car_categories) 안에 있으면 num+=1 & break
            #각 이미지 데이터의 get_predictions의 top5와 car_categories를 비교하여 최대 value 값이 5가 될 수 있음
                num += 1
                break # breaks out of for loop if one of top 50 categories is found
            else:
                pass
            failed_img.append(img_path) # appends to "bad list" if none of the 50 are found
            #car_categories 안에 j[0:2]가 없을 때마다 그 이미지 파일을 failed_img에 추가. 총 prediction 값이 car_categories 안에 없을 때마다 failed_img에 추가
        if i % 100 == 0:
            print(i, "/", len(img_list), "complete")
    #print(Counter(failed_img))
    #print(Counter(failed_img).items())
    failed_img = [k for k, v in Counter(failed_img).items() if v == 5]
    #failed_img.append 하면서 
    #print(failed_img)
    return num, failed_img

number, failed_img = evaluate_car_categories(car_categories)

# ## Select top 50 as cutoff for category list

def view_images(img_dir, img_list):
    for img in img_list:
        clear_output()
        display(Image(img_dir+img))
        num = raw_input("c to continue, q to quit")
        if num == 'c':
            pass
        else:
            return 'Finished for now.'

#view_images('data/', failed_img)


#view_images('data/', failed_img2)


#Gate Implementation

def car_categories_gate1(image_path, car_categories):
    out = vgg16.predict(image_path)
    top = get_predictions(out, top=5)
    print("Validating that this is a picture of your car...")
    for j in top[0]:
        if j[0:2] in car_categories:
            print(j[1:])
            return "Validation complete - proceed to damage evaluation"
    return "try again"


def car_categories_gate(image_path, car_categories):
    urllib.request.urlretrieve(image_path, "save.jpg") # or other way to upload image
    img = prepare_image("save.jpg")
    out = vgg16.predict(img)
    top = get_predictions(out, top=5)
    print("Validating that this is a picture of your car...")
    for j in top[0]:
        if j[0:2] in car_categories:
            print(j[1:2])
            return "Validation complete - proceed to damage evaluation"
    return "Are you sure this is a picture of your car? Please take another picture (try a different angle or lighting) and try again."


#car_categories_gate("https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcSxhKhaSwPgdQkrDegC6sbUALBF9SiW6tDKg6dLDYj83e19krxy", cat_list)

#car_categories_gate("https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS7xHO3j12Xk4q4eaQUL1A02k1HrJ9G_RY6tj-4h-07EfdML6YL", cat_list)
im = prepare_image(root_dir + "data1" + "/0134.jpg")
car_categories_gate1(im, car_categories)
```
