---
layout: post
title:  "AIXDL 프로젝트 - code gate2"
summary: "차량 공유 서비스의 차량 파손 여부를 CNN을 활용하여 판단"
author: taehun
date: '2020-12-08 04:13:00 +0900'
category: Python
toc : true
toc_sticky : true
thumbnail: /assets/img/posts/thumbnail-3.png
keywords: AI+X:DeepLearning, Dataset, VGGNet, Pre-trained model, ImageNet
permalink: /blog/project-1
---
----------
## Code Analysis Gate 2
Framework : tensorflow2, keras2
----------
```python
#!/usr/bin/env python
# coding: utf-8

# ### data2 - whole cars vs. all damaged cars

# In[1]:

import urllib
from IPython.display import Image, display, clear_output
from collections import Counter

import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import Image, display, clear_output
# get_ipython().run_line_magic('matplotlib', 'inline')

import json
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

sns.set_style('whitegrid')


# In[2]:


import os
import h5py
import numpy as np
import pandas as pd

from keras.applications.vgg16 import VGG16
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
# from keras.regularizers import l2, activity_l2, l1, activity_l1
from keras.regularizers import l2,l1
from keras.models import Sequential, load_model
from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Conv2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.utils.np_utils import to_categorical
from keras import optimizers
from keras.callbacks import ModelCheckpoint, History


root_dir = "/home/ubuntu/project/"
vgg16 = VGG16(weights='imagenet')
vgg16.save_weights(root_dir + 'vgg16_weights.h5')
# def load_vgg16(weights_path='../vgg16_weights.h5'):
def load_vgg16(weights_path='./vgg16_weights.h5'):
    model = Sequential()
    model.add(ZeroPadding2D((1,1),input_shape = (img_width, img_height,3)))
    #padding = 'same' 옵션은 padding을 추가하여 input과 output의 크기를 똑같이 만드는 것. 
    #padding = 'valid' 옵션은 filter에 의해 output의 크기가 줄어들도록 만드는 것. 즉, padding을 하지 않는 것
    model.add(Conv2D(64, (3, 3), padding = 'same', activation='relu'))
    #Conv2D(output 개수, fileter size, strides), 일반적으로 출력 데이터의 size는 (N-F)/stride+1임. 이 때 N은 input image의 size, F는 filter size.
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(64, (3, 3), padding = 'same',activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(128, (3, 3), padding = 'same',activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(128, (3, 3), padding = 'same',activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(256, (3, 3), padding = 'same',activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(256, (3, 3), padding = 'same',activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(256, (3, 3), padding = 'same',activation='relu'))
    #아래 maxpooling부터 오류 발생 size 문제가 있음
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), padding = 'same',activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), padding = 'same',activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), padding = 'same',activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), padding = 'same',activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), padding = 'same',activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), padding = 'same',activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))


    model.layers[1].set_weights(vgg16.layers[1].get_weights())
    model.layers[3].set_weights(vgg16.layers[2].get_weights())
    model.layers[6].set_weights(vgg16.layers[4].get_weights())
    model.layers[8].set_weights(vgg16.layers[5].get_weights())
    model.layers[11].set_weights(vgg16.layers[7].get_weights())
    model.layers[13].set_weights(vgg16.layers[8].get_weights())
    model.layers[15].set_weights(vgg16.layers[9].get_weights())
    model.layers[18].set_weights(vgg16.layers[11].get_weights())
    model.layers[20].set_weights(vgg16.layers[12].get_weights())
    model.layers[22].set_weights(vgg16.layers[13].get_weights())
    model.layers[25].set_weights(vgg16.layers[15].get_weights())
    model.layers[27].set_weights(vgg16.layers[16].get_weights())
    model.layers[29].set_weights(vgg16.layers[17].get_weights())

    return model


def save_bottleneck_features(location):
    datagen = ImageDataGenerator(rescale=1./255)
    #ImageDataGenerator는 데이터 전처리 과정
    
    model = load_vgg16()
    batch_size = 16
    generator = datagen.flow_from_directory(train_data_dir,
                                            target_size=(img_width, img_height),
                                            batch_size=batch_size, 
                                            class_mode=None, 
                                            shuffle=False)
                                            #data를 기존 label 순서에 따라 두는 것 
    print("generator : ",generator.class_indices)
    # print("len(generator) : ",len(generator)) image data 개수 / batch_size
    steps_tr = nb_train_samples/batch_size
    # bottleneck_features_train = model.predict_generator(generator, nb_train_samples)
    bottleneck_features_train = model.predict_generator(generator, steps_tr)
    print("nb_train_samples : ",nb_train_samples) #얘까지는 600개
    # print("bottleneck_features_train : ",len(bottleneck_features_train)) bottleneck_features_train이 9480개 colab에서는 600개라고 뜸
    print(bottleneck_features_train.shape)
    np.save(open(location+"/bottleneck_features_train.npy", 'wb'), bottleneck_features_train)

    # repeat with the validation data
    generator = datagen.flow_from_directory(validation_data_dir,
                                           target_size=(img_width, img_height),
                                           batch_size=batch_size,
                                           class_mode=None,
                                           shuffle=False)
    steps_val = nb_validation_samples/batch_size
    # bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples)
    bottleneck_features_validation = model.predict_generator(generator, steps_val)
    np.save(open(location+"/bottleneck_features_validation.npy", 'wb'), bottleneck_features_validation)


def plot_metrics(hist, stop=50):
    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,4))
                            
    axes = axes.flatten()

    axes[0].plot(range(stop), hist['accuracy'], label='Training', color='#FF533D')
    axes[0].plot(range(stop), hist['val_accuracy'], label='Validation', color='#03507E')
    axes[0].set_title('Accuracy')
    axes[0].set_ylabel('Accuracy')
    axes[0].set_xlabel('Epoch')
    axes[0].legend(loc='lower right')
                             
    axes[1].plot(range(stop), hist['loss'], label='Training', color='#FF533D')
    axes[1].plot(range(stop), hist['val_loss'], label='Validation', color='#03507E')
    axes[1].set_title('Loss')
    axes[1].set_ylabel('Loss')
    axes[1].set_xlabel('Epoch')
    axes[1].legend(loc='upper right')
                             
    plt.tight_layout();
    
    print("Best Model:") 
    print_best_model_results(hist)

#아래 코드 colab에서는 필요없음
class NumpyEncoder(json.JSONEncoder):
    """ Special json encoder for numpy types """
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)

def train_binary_model():

    train_data = np.load(open(location+"/bottleneck_features_train.npy",'rb'))
    print(train_data.shape)
    print(type(train_samples))
    print("train_samples : ",train_samples)
    print("train_samples[0] : ", train_samples[0])
    print("train_samples[1] : ", train_samples[1])
    # print("train_samples[2] : ", train_samples[2])
    train_labels = np.array([0] * train_samples[0] + 
                            [1] * train_samples[1])

    print("validation_samples[0] : ", validation_samples[0])
    print("validation_samples[1] : ", validation_samples[1])
    print("train_data : ", len(train_data))


    validation_data = np.load(open(location+"/bottleneck_features_validation.npy",'rb'))
    validation_labels = np.array([0] * validation_samples[0] + 
                                 [1] * validation_samples[1])
    
    model = Sequential()
    model.add(Flatten(input_shape=train_data.shape[1:])) # 512, 4, 4
    model.add(Dense(256, activation = 'relu', kernel_regularizer=l2(0.001)))
    model.add(Dropout(0.5))
    model.add(Dense(1, activation = 'sigmoid')) # should activation be sigmoid for binary problem?

    model.compile(optimizers.SGD(lr=0.0001, momentum=0.9),
              loss='binary_crossentropy', metrics=['accuracy'])

    
    checkpoint = ModelCheckpoint(top_model_weights_path, monitor='val_acc', 
                                 verbose=1, save_best_only=True, save_weights_only=True, mode='auto')

    batch_size = 16
    fit = model.fit(train_data, train_labels,
              epochs=nb_epoch, batch_size=batch_size,
              validation_data=(validation_data, validation_labels),
              callbacks=[checkpoint])
    #aws 버전(Typeerror : object of tyoe float32 is not JSON serializable error)
    fit_history = json.dumps(fit.history, cls =NumpyEncoder)
    with open(location+'/top_history.txt', 'w') as f:
        json.dump(fit_history, f)

    # #colab 버전
    # with open(location+'/top_history.txt','w') as f:
    #     json.dump(fit.history,f)
    
    return model, fit.history


def finetune_binary_model():
    model = load_vgg16()

    # build a classifier model to put on top of the convolutional model
    top_model = Sequential()
    top_model.add(Flatten(input_shape=model.output_shape[1:]))
    top_model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))
    top_model.add(Dropout(0.5))
    top_model.add(Dense(1, activation='sigmoid'))

    top_model.load_weights(top_model_weights_path) # load weights_path

    # add the model on top of the convolutional base
    model.add(top_model)
    
    # set the first 25 layers (up to the last conv block)
    # to non-trainable - weights will not be updated
    for layer in model.layers[:25]:
        layer.trainable=False

    # compile the model with a SGD/momentum optimizer 
    # and a very slow learning rate
    model.compile(loss='binary_crossentropy',
                 optimizer = optimizers.SGD(lr=0.00001, momentum=0.9), # reduced learning rate by 1/10
                  metrics=['accuracy'])
    
    # prepare data augmentation configuration
    train_datagen = ImageDataGenerator(rescale=1./255,
                                       rotation_range=40,
                                       width_shift_range=0.2,
                                       height_shift_range=0.2,
                                       shear_range=0.2,
                                       zoom_range=0.2,
                                       horizontal_flip=True,
                                       fill_mode='nearest')

    test_datagen = ImageDataGenerator(rescale=1./255)

    batch_size = 8

    train_generator= train_datagen.flow_from_directory(train_data_dir,
                                                     target_size=(img_height, img_width),
                                                     batch_size=batch_size,
                                                     class_mode='binary')

    validation_generator = test_datagen.flow_from_directory(validation_data_dir,
                                                           target_size=(img_height, img_width),
                                                           batch_size=batch_size,
                                                           class_mode='binary')
    
    
    checkpoint = ModelCheckpoint(fine_tuned_model_path, monitor='val_acc', 
                                 verbose=1, save_best_only=True, 
                                 save_weights_only=False, mode='auto')
    steps_tr = nb_train_samples / batch_size
    steps_val = nb_validatioan_samples / batch_size
    # fine-tune the model
    fit = model.fit_generator(train_generator,
                              steps_per_epoch=steps_tr,
                              epochs=nb_epoch,
                              validation_data=validation_generator,
                              validation_steps=steps_val,
                              verbose=1,
                              callbacks=[checkpoint])
    #aws 버전
    fit_history = json.dumps(fit.history, cls=NumpyEncoder)
    with open(location+'/ft_history.txt','w') as f:
        json.dump(fit_history, f)

    # #colab 버전    
    # with open(location+'/ft_history.txt', 'w') as f:
    # #with open('file_path','w') as f: 는 file path에 쓰기 모드로 파일을 생성하는 것. 이 때 저장될 파일을 f라고 칭함
    # #json.dump(fit.history, f)는 위에서 model.fit으로 생성된 모델의 fit.history를 f에 저장한다는 것
    #     json.dump(fit.history, f)
    
    return model, fit.history

def evaluate_binary_model(model, directory, labels):
    datagen = ImageDataGenerator(rescale=1./255)  
    batch_size = 8
    generator = datagen.flow_from_directory(directory,
                                target_size=(img_height, img_width),
                                batch_size=batch_size,
                                class_mode='binary', # categorical for multiclass
                                shuffle=False)
    steps_ev = len(labels)/batch_size
    predictions = model.predict_generator(generator, steps_ev)
    
    # use for multiclass
    # pred_labels = np.argmax(predictions, axis=1)
    
    pred_labels = [0 if i <0.5 else 1 for i in predictions]

    print(classification_report(validation_labels, pred_labels))
    cm = confusion_matrix(validation_labels, pred_labels)
    sns.heatmap(cm, annot=True, fmt='g');


def view_images(img_dir, img_list):
    for img in img_list:
        clear_output()
        display(Image(img_dir+img))
        num = input("c to continue, q to quit")
        if num == 'c':
            pass
        else:
            return 'Finished for now.'

def print_best_model_results(model_hist):
    best_epoch = np.argmax(model_hist['val_accuracy'])
    print("epoch:", best_epoch+1,     ", val_acc:", model_hist['val_accuracy'][best_epoch],     ", val_loss:", model_hist['val_loss'][best_epoch])


# ## Testing Image Generation

datagen = ImageDataGenerator(rotation_range=40,
                             width_shift_range=0.2,
                             height_shift_range=0.2,
                             shear_range=0.2,
                             zoom_range=0.2,
                             horizontal_flip=True,
                             fill_mode='nearest') # omitted rescaling to keep the images displayable

img = load_img(root_dir + "data2/training/00-damage/0039.JPEG") # this is a PIL image 
x = img_to_array(img) # this is a Numpy array with shape (3, 150, 150)
x = x.reshape((1,) + x.shape) # this is a Numpy array with shape (1, 3, 150, 150)

# the .flow() command below generates batches of randomly transformed images
# and saves the results to the 'preview/' directory
# os.makedirs(root_dir + "data2_preview")
# 위 코드는 한번만 실행할 것

i = 0
for batch in datagen.flow(x, batch_size=1,
                         save_to_dir=root_dir+"data2_preview", save_prefix="damage_car",
                         save_format="jpeg"):
    i +=1
    if i > 30:
        break # otherwise the generator would loop indefinitely


#view_images(root_dir + "data2_preview/", os.listdir(root_dir + "data2_preview/"))


# ## Defining input data

# path to the model weights file
location = root_dir + "data2"
top_model_weights_path=location+"/top_model_weights.h5" # will be saved into when we create our model
# model_path = location + '/initial_data2_model.h5'
fine_tuned_model_path = location+"/ft_model.h5"

# dimensions of our images
img_width, img_height = 256, 256

train_data_dir = location+"/training"
validation_data_dir = location+"/validation"

print(sorted(os.listdir(train_data_dir)))
trian_samples = []
train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]
print("train_samples : ",train_samples)
nb_train_samples = sum(train_samples)
validation_samples = [len(os.listdir(validation_data_dir+'/'+i)) for i in sorted(os.listdir(validation_data_dir))]
nb_validation_samples = sum(validation_samples)

nb_epoch = 50


# do not rerun!!
save_bottleneck_features(location)

d1a_model1, d1a_history1 = train_binary_model()



plot_metrics(d1a_history1) # rmsprop, sigmoid, no regularization


# ## Fine Tuning

ft_model, ft_history = finetune_binary_model()

plot_metrics(ft_history) # sgd with lr = 0.0001, sigmoid, with l2 = 0.001

# ## Load Model Point


ft_model = load_model(location+'/ft_model.h5')

with open(root_dir + 'data2/top_history.txt') as f:
    top_history = json.load(f)

with open(root_dir + 'data2/ft_history.txt') as f:    
    ft_history = json.load(f)


def plot_metrics(hist, stop=50):
    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,4))
                            
    axes = axes.flatten()

    axes[0].plot(range(stop), hist['accuracy'], label='Training', color='#FF533D')
    axes[0].plot(range(stop), hist['val_accuracy'], label='Validation', color='#03507E')
    axes[0].set_title('Accuracy')
    axes[0].set_ylabel('Accuracy')
    axes[0].set_xlabel('Epoch')
    axes[0].legend(loc='lower right')
                             
    axes[1].plot(range(stop), hist['loss'], label='Training', color='#FF533D')
    axes[1].plot(range(stop), hist['val_loss'], label='Validation', color='#03507E')
    axes[1].set_title('Loss')
    axes[1].set_ylabel('Loss')
    axes[1].set_xlabel('Epoch')
    axes[1].legend(loc='upper right')
                             
    plt.tight_layout();
    
    print("Best Model:") 
    print_best_model_results(hist)


def plot_acc_metrics(hist1, hist2, stop=50):
    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(4.25,6))
                            
    axes = axes.flatten()
    
    axes[0].plot(range(stop), hist1['accuracy'], label='Training', color='#FF533D')
    axes[0].plot(range(stop), hist1['val_accuracy'], label='Validation', color='#03507E')
    axes[0].set_title('Training')
    axes[0].set_ylabel('Accuracy')
    axes[0].set_xlabel('Epoch')
    axes[0].legend(loc='lower right')
                             
    axes[1].plot(range(stop), hist2['accuracy'], label='Training', color='#FF533D')
    axes[1].plot(range(stop), hist2['val_accuracy'], label='Validation', color='#03507E')
    axes[1].set_title('Fine-tuning')
    axes[1].set_ylabel('Accuracy')
    axes[1].set_xlabel('Epoch')
    axes[1].legend(loc='lower right')
                             
    plt.tight_layout();


def evaluate_binary_model(model, directory, labels):
    datagen = ImageDataGenerator(rescale=1./255)  
    batch_size = 8
    generator = datagen.flow_from_directory(directory,
                                target_size=(img_height, img_width),
                                batch_size=batch_size,
                                class_mode='binary', # categorical for multiclass
                                shuffle=False)
    steps_ev = len(labels)/batch_size
    predictions = model.predict_generator(generator, steps_ev)
    
    # use for multiclass
    # pred_labels = np.argmax(predictions, axis=1)
    
    pred_labels = [0 if i <0.5 else 1 for i in predictions]

    print(classification_report(validation_labels, pred_labels))
    cm = confusion_matrix(validation_labels, pred_labels)
    return cm 


plot_acc_metrics(top_history, ft_history)


plot_metrics(ft_history) # sgd with lr = 0.0001, sigmoid, with l2 = 0.001


validation_labels = np.array([0] * validation_samples[0] + 
                             [1] * validation_samples[1])

cm = evaluate_binary_model(ft_model, validation_data_dir, validation_labels)


heatmap_labels = ['Damaged', 'Whole']


sns.heatmap(cm, annot=True, annot_kws={"size": 16}, 
            fmt='g', cmap='OrRd', xticklabels=heatmap_labels, yticklabels=heatmap_labels);

sns.heatmap(cm, annot=True, annot_kws={"size": 16}, 
            fmt='g', cmap='Blues', xticklabels=heatmap_labels, yticklabels=heatmap_labels);


# ## Making Live Predictions

def car_categories_gate(image_path, model):
    urllib.request.urlretrieve(image_path, 'save.jpg') # or other way to upload image
    img = load_img('save.jpg', target_size=(256, 256)) # this is a PIL image 
    x = img_to_array(img) # this is a Numpy array with shape (3, 256, 256)
    x = x.reshape((1,) + x.shape)/255 # this is a Numpy array with shape (1, 3, 256, 256)
    pred = model.predict(x)
    print("Validating that damage exists...")
    print(pred)
    if pred[0][0] <=.5:

        print("Validation complete - proceed to location and severity determination")
    else:
        print("Are you sure that your car is damaged? Please submit another picture of the damage.")
        print("Hint: Try zooming in/out, using a different angle or different lighting")



Image('https://www.nerdwallet.com/blog/wp-content/uploads/2015/12/exterior-car-damage-384x233.jpg')


car_categories_gate('https://www.nerdwallet.com/blog/wp-content/uploads/2015/12/exterior-car-damage-384x233.jpg', ft_model)


Image('http://1.bp.blogspot.com/-ToQS-qIxYbo/UDNuV5OcVQI/AAAAAAAABdo/tjeQywWiOo0/s200/Key+scratch.jpg')

car_categories_gate('http://1.bp.blogspot.com/-ToQS-qIxYbo/UDNuV5OcVQI/AAAAAAAABdo/tjeQywWiOo0/s200/Key+scratch.jpg', ft_model)

# ## Looking at edge cases

def get_edge_cases(model, directory, exp_result):
    img_list = os.listdir(directory)
    edge_list = []
    for name in img_list:
        img = load_img(directory+name, target_size=(256, 256)) # this is a PIL image 
        x = img_to_array(img) # this is a Numpy array with shape (3, 256, 256)
        x = x.reshape((1,) + x.shape)/255 # this is a Numpy array with shape (1, 3, 256, 256)
        pred_prob = model.predict(x)
        if pred_prob <=0.5:
            pred = 0
        else:
            pred = 1
        if pred != exp_result:
            edge_list.append(name)
    return edge_list

evaluate_binary_model(ft_model, validation_data_dir, validation_labels)
# TP = 221, TN = 194, FP = 36, FN = 9
# 9 were predicted to be damaged but were actually whole
# 36 were predicted to be whole but were actually damaged

fp = get_edge_cases(ft_model, root_dir + 'data2/validation/00-damage/', 0)


view_images(root_dir + 'data2/validation/00-damage/', fp)  # damaged, identifed as whole


# In[73]:


fn = get_edge_cases(ft_model, root_dir + 'data2/validation/01-whole/', 1)


# In[76]:


view_images(root_dir + 'data2/validation/01-whole/', fn) #whole, identified as damaged

```
