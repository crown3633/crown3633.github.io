---
layout: post
title:  "AIXDL Project"
summary: "차량 공유 서비스의 차량 파손 여부를 CNN을 활용하여 판단"
author: taehun
date: '2020-12-02 16:53:00 +0900'
category: Python
toc : true
toc_sticky : true
thumbnail: /assets/img/posts/thumbnail-1.png
keywords: AI+X:DeepLearning, Dataset, VGGNet, Pre-trained model, ImageNet
permalink: /blog/project
---
----------
## **Index**
----------
<a href="#Introduction">**1. Introduction**</a>
- 필요성
- 목표<br><br>
 
<a href="#Dataset">**2. Dataset**</a>
- 사용한 데이터셋
- 데이터 전처리 <br><br>
 
<a href="#VGGNet">**3. VGGNet Model**</a> <br><br>
 
<a href="#Code">**4. Code Analysis**</a> <br>
- <a href="#Gate1">Gate 1. 이미지 데이터의 차량 여부 판단(Pre-trained VGG16 model)</a> <br>

- <a href="#Gate2">Gate 2. 차량의 파손 여부 판단(Transfer Learning & Fine Tuning)</a> <br><br>

<a href="#Evaluation">**5. Evaluation**</a> <br><br>

<a href="#Conclusion">**6. Conclusion & Improvement**</a> <br><br>

-----------
## <a name="Introduction">1. Introduction</a>
-----------

#### 1) 필요성
 - 미래 모빌리티 산업에서 공유 서비스는 핵심 개념 중 하나이다. 대표적인 예로 '쏘카', '그린카' 등의 차량 공유 서비스뿐만 아니라, '따릉이','beam','씽씽'과 같은 자전거, 전동 킥보드의 공유 서비스도 있다. 공유서비스의 대상인 차량, 킥보드 등은 단독으로 소유하는 소유물이 아니기에, 파손 및 손상 여부에 대한 과실 판정을 제 때에, 정확하게 할 필요가 있다.<br><br> 렌트카의 경우 대여 및 반납시 대여자가 차량의 파손여부를 직접 체크한다. 차량 확인 과정에서 발견하지 못한, 즉 대여자의 과실이 아닌 손상으로 인해 발생하는 문제를 확실히 해결하기 위해서는 적절한 시스템이 필요할 것이다. 이 문제점을 해결하기 위해서 딥러닝의 이미지 분류를 이용해서 해결해보고자 한다.<br><br>

#### 2) 목표
 - 본 프로젝트에서는 딥러닝의 Image Classification을 활용해서 문제를 해결하고자 한다. 임의의 이미지 데이터를 입력했을 때 차량인지 아닌지를 판단하고, 만약 차량이 맞다면 차량의 파손 유무를 판단하는 것이 프로젝트의 최종 목표이다. <br><br> 판단은 2개의  Gate를 통해 이루어진다. Gate1에서는  Pre-trained model(VGGNet )을 활용하여 차량 여부 및 차량의 종류를 판단하고, Gate2에서는 직접 학습시킨 모델로  파손 여부를 판단한다.<br><br>
 
<div style="width:700px; height:300px;">
 <img src="/assets/img/Gate.png" width="700px" height="300px">
 <figcaption style="text-align:center">모델 알고리즘 개략도</figcaption>
</div><br><br>
 
----------------
## <a name="Dataset">2. Dataset</a>
----------------

#### 1) 사용 데이터셋
- data1 폴더 : Normal/Damaged 차량에 대한 이미지 파일 각 500개, 총 1000개(Gate1)
- data2 폴더 : Training data 600개(Normal/Damaged 각 300개)<br>　　 　　　　Validation data 200개(Normal/Damaged 각 100개)(Gate2)<br>

<div style="width:300px; height:300px; float:left; margin-right:10px;">
 <img src="/assets/img/normal.jpg" width="300px" height="300px">
 <figcaption style="text-align:center">Normal car image</figcaption>
</div>
<div style="width:300px; height:303px; float:left;">
 <img src="/assets/img/damaged.jpg" width="300px" height="303px">
 <figcaption style="text-align:center">Damaged car image</figcaption>
</div><div style="clear:both;"></div><br><br>

#### 2) 데이터 전처리 과정

```python
def prepare_image(img_path):
    img = load_img(img_path, target_size=(224, 224))
    x = img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    return x
```

- Pre-trained VGG16 model에서 학습된 image size는 224×224이므로, input image를 224×224로 변환하는 과정<br><br>

-------------------
## <a name="VGGNet">3. VGGNet Model</a>
-------------------
<img src="/assets/img/VGGNet.png" width="700px" height="300px"><br><br>
 
-----------------
## <a name="Code">4. Code Analysis</a>
-----------------

#### <a name="Gate1">Gate 1. 이미지 데이터의 차량 여부 판단(Pre-trained VGG16 model)</a>
- Gate 1은 Normal/Damaged car를 구분하기 전에 Input image가 차량인지 아닌지를 구별하기 위함<br><br>
**`1)get_predictions(preds,top=5) function`**

```python
def get_predictions(preds, top=5):
    global CLASS_INDEX
    if len(preds.shape) != 2 or preds.shape[1] != 1000:
        raise ValueError('`decode_predictions` expects '
                         'a batch of predictions '
                         '(i.e. a 2D array of shape (samples, 1000)). '
                         'Found array with shape: ' + str(preds.shape))
    if CLASS_INDEX is None:
        fpath = get_file('imagenet_class_index.json',
                         CLASS_INDEX_PATH,
                         cache_subdir='models')
        CLASS_INDEX = json.load(open(fpath))
    results = []
    for pred in preds:
        top_indices = pred.argsort()[-top:][::-1]
        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]
        list_A = []
        for k in range(top):
        	list_A.append(result[i][1:])
        result.sort(key=lambda x: x[2], reverse=True)
        results.append(result)
    return results
```
```python
vgg16 = VGG16(weights='imagenet')

y = prepare_image('image_file.jpg')
preds = vgg16.predict(y)
print(get_predictions(preds, top=5))
```
- get_predictions(preds, top=5) 결과<br>
`[('racer', 0.6540158), ('sports_car', 0.26624563), ('convertible', 0.028868116), ...]`<br>

- 변수 preds는 data1 폴더의 dataset을 resizing 후 VGG16(weight='imagenet')으로 예측한 결과물이며, 1000개의 class에 대한 확률값을 나타내기에 차원은 (1,1000)이다.
- get_prediction 함수는 예측한 class 중 상위 5개의 class name과 확률값을 반환한다.<br><br>

　 **`2)get_car_categories() function`**
```python
def get_car_categories():
    d = defaultdict(float)
    img_list = os.listdir("data1")
    for i, img_path in enumerate(img_list):
        img = prepare_image(root_dir + "data1/"+ img_path)
        out = vgg16.predict(img)
        top = []
        # for i in range(5):
        # 	top.append(get_predictions(out,top=5)[0][i][1:])
        top = get_predictions(out, top=5)
        for j in top[0]:
            d[j[0:2]] += j[2]
            #d[j[1:2]] += j[2]
        if i % 100 == 0:
            print(i, "/" , len(img_list), "complete")
    print("Done\n")
    return Counter(d)
```  
- 해당 디렉토리에 있는 input 이미지에 대해 top5 class와 probability를 구해서 누적 합산하는 함수.
- top[0]에는 3가지 성분이 있음. 1000개 class중 고유 이름(j[0] : ex)'n5324', j[1] : class의 이름(label) ex)'sports car', j[2] : 확률값 ex)0.938402)
- 결국, 디렉토리 내에 있는 이미지 파일들 중 가장 빈번하게 등장하는 class들을 찾기 위함<br><br>

```python
car_categories_all = get_car_categories()
car_categories = [k for k, v in car_categories_all.most_common()[:50]]
```

- get_car_categories로 얻은 list중 key값이 큰 순서대로 상위 50개를 선택하여 car_categories에 저장<br>
`[('minivan',129.24480718624545), ('sports_car', 85.58487360691652), ('convertible', 71.450213502687), ('pickup', 62.12108225026168), ...]`
<figcaption style="text-align:center">위와 같은 형태로 50개가 출력됨</figcaption><br><br>

　 **`3)evaluate_car_categories(car_categories) function`**
```python
def evaluate_car_categories(car_categories):
    img_list = os.listdir("data1")
    num = 0
    failed_img = []
    for i, img_path in enumerate(img_list):
        img = prepare_image("data1/"+img_path)
        out = vgg16.predict(img)
        if i==1: print(out.shape)
        top = get_predictions(out, top=5)
        for j in top[0]:
            if j[0:2] in car_categories:
                num += 1
                break # breaks out of for loop if one of top 50 categories is found
            else:
                pass
            failed_img.append(img_path) # appends to "bad list" if none of the 50 are found
        if i % 100 == 0:
            print(i, "/", len(img_list), "complete")
    failed_img = [k for k, v in Counter(failed_img).items() if v == 5]
    return num, failed_img
```

- evaluate_car_categories 함수는 위에서 한번 분류한 car_categories를 가지고 failed_img를 찾아내는 함수
- input image에 대한 top5 prediction 중 어느 것도 car_categories안에 포함되지 않는다면 failed_img 리스트에 저장된다.

```python
print(failed_img)
```

　 `['1044.jpg', '1205.jpg', '1102.jpg', '1354.jpg']`
<br><br>
- **Failed_img 확인**
<div style="width:200px; height:300px; float:left; margin-right:10px;">
 <img src="/assets/img/failed_img1.png" width="200px" height="300px">
</div>
<div style="width:200px; height:300px; float:left;">
 <img src="/assets/img/failed_img2.png" width="200px" height="300px">
</div><div style="clear:both;"></div><br>

- 총 1,000개의 dataset에서 4개의 경우만 차량으로 인식하지 못한 것이므로 높은 정확도를 가진다.
- 하지만 극히 드물게 failed_img와 같이 여러 사물이 있는 경우, 혹은 차량의 일부만 나온 경우는 인식하지 못하는 경우가 있다.<br>
--> **Pre-trained VGG16을 이용해서 Nomal/Damaged car image 모두 높은 확률로 차량을 구별할 수 있다.** <br><br>

#### <a name="Gate2">Gate 2. 차량의 파손 여부 판단(Transfer Learning & Fine Tuning)</a><br>

　 **`1) load_vgg16() function`**
  
```python
def load_vgg16():
    vgg16 = VGG16(weights='imagenet')
    vgg16.save_weights('
    model = Sequential()
    model.add(ZeroPadding2D((1,1),input_shape = (img_width, img_height,3)))
    model.add(Conv2D(64, (3, 3), padding = 'same', activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(64, (3, 3), padding = 'same',activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    ...

    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), padding = 'same',activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), padding = 'same',activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), padding = 'same',activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))
    
    #Transfer Learning 과정.
    model_conv_layer=[]
    vgg16_conv_layer=[]

    for j in range(len(model.layers)):
      if str(model.layers[j]).find("Conv2D")!=-1:
        model_conv_layer.append(j)

    for k in range(len(vgg16.layers)):
      if str(vgg16.layers[k]).find("Conv2D")!=-1:
        vgg16_conv_layer.append(k)

    for j, k in zip(model_conv_layer,vgg16_conv_layer):
      model.layers[j].set_weights(vgg16.layers[k].get_weights())
      
    return model
```

- VGG16 model은 Convolutional layer와 Fully connected layer를 합쳐서 16-layers이며, Padding, Pooling layer의 배치로 다양한 모델을 만들 수 있다.
- 아래 Transfer Learning 과정은 Pre-trained VGG16 model에서 Convolutional layer의 weight를 load_vgg16()을 통해 쌓은 model의 Convolutional layer에 weight를 인가하는 과정이다.<br>

　 **`2) train_binary_model(batch_size) function`**
  
```python
def train_binary_model(batch_size):

    train_data = np.load(open(location+"/bottleneck_features_train.npy",'rb'))
    train_labels = np.array([0] * train_samples[0] + 
                            [1] * train_samples[1])

    validation_data = np.load(open(location+"/bottleneck_features_validation.npy",'rb'))
    validation_labels = np.array([0] * validation_samples[0] + 
                                 [1] * validation_samples[1])
    # batch_size = 16
    
    model = Sequential()
    model.add(Flatten(input_shape=train_data.shape[1:])) # 512, 4, 4
    print(model.summary())
    model.add(Dense(256, activation = 'relu', kernel_regularizer=l2(0.001)))
    model.add(Dropout(0.5)) 
    model.add(Dense(1, activation = 'sigmoid')) # should activation be sigmoid for binary problem?

    model.compile(optimizers.SGD(lr=0.0001, momentum=0.9),
              loss='binary_crossentropy', metrics=['accuracy'])

    
    checkpoint = ModelCheckpoint(top_model_weights_path, monitor='val_accuracy', 
                                 verbose=1, save_best_only=True, save_weights_only=True, mode='auto')

    fit = model.fit(train_data, train_labels,
                    epochs = nb_epoch, batch_size = batch_size,
                    validation_data = (validation_data, validation_labels),
                    callbacks=[checkpoint])

    with open(location+'/top_history.txt', 'w') as f:
        json.dump(fit.history, f)
    
    return model, fit.history
```
